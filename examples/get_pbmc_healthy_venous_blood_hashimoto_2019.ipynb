{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import scvi\n",
    "from scvi.dataset import GeneExpressionDataset\n",
    "import numpy\n",
    "import sparsedat\n",
    "from sparsedat import wrappers \n",
    "from sparsedat import Data_Type\n",
    "from sparsedat import Sparse_Data_Table as SDT\n",
    "import scipy\n",
    "from scvi.models.vae import VAE\n",
    "from scvi.inference import UnsupervisedTrainer\n",
    "from scvi.models.scanvi import SCANVI\n",
    "from plotly import offline as plotly\n",
    "from sklearn.manifold import TSNE\n",
    "from plotly import graph_objects\n",
    "from umap import UMAP\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from sparsedat import wrappers\n",
    "from scipy.sparse import coo_matrix, vstack\n",
    "import itertools\n",
    "from numpy import load\n",
    "import random\n",
    "import os\n",
    "from scvi import set_seed\n",
    "import pickle\n",
    "import anndata\n",
    "from scrapi.dataset import Gene_Expression_Dataset as GED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1040"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get healthy venous blood PBMC scRNA-seq data from Hashimoto (2019) dataset (https://www.pnas.org/content/116/48/24242#sec-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashimoto_barcodes = pd.read_csv(os.path.join('data', 'Hashimoto2019', 'cell_barcodes.txt'), sep = '\\t',header=None)\n",
    "hashimoto_barcodes = hashimoto_barcodes.drop([2],axis=1)\n",
    "hashimoto_barcodes.columns = ['barcode','sample_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(\"data\", \"Hashimoto2019\", \"hashimoto.mtx\")):\n",
    "\n",
    "    # Grabbing the raw counts for study in order to feed into scvi\n",
    "    sdt = wrappers.load_text(\n",
    "        os.path.join(\"data\", \"Hashimoto2019\", \"01.UMI.txt\"),\n",
    "        separator=\"\\t\",\n",
    "        has_header=True,\n",
    "        has_row_names=True,\n",
    "        default_value=0,\n",
    "        data_type=Data_Type.INT\n",
    "    )\n",
    "    \n",
    "    sdt.transpose()\n",
    "\n",
    "    sdt.save(os.path.join(\"data\", \"Hashimoto2019\", \"01.UMI.sdt\"))\n",
    "    \n",
    "    sdt = SDT(os.path.join(\"data\", \"Hashimoto2019\", \"01.UMI.sdt\"))\n",
    "    \n",
    "    wrappers.to_mtx(\n",
    "        sdt,\n",
    "        os.path.join(\"data\", \"Hashimoto2019\", \"barcodes.txt\"),\n",
    "        os.path.join(\"data\", \"Hashimoto2019\", \"genes.txt\"),\n",
    "        os.path.join(\"data\", \"Hashimoto2019\", \"hashimoto.mtx\"),\n",
    "        column_based=False\n",
    "    )\n",
    "else:\n",
    "    sdt = SDT(os.path.join(\"data\", \"Hashimoto2019\", \"01.UMI.sdt\"))\n",
    "\n",
    "hashimoto_mtx = anndata.read_mtx(os.path.join(\"data\", \"Hashimoto2019\", \"hashimoto.mtx\"))\n",
    "hashimoto_mtx = hashimoto_mtx.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = pd.read_csv(os.path.join(\"data\", \"Hashimoto2019\", \"genes.txt\"), sep = '\\t',header=None)\n",
    "gene_ensg_array = genes[0].values\n",
    "\n",
    "# Get the corresponding values for ensg labels in hashimoto data from hu's data (ensg->gene name mapping)\n",
    "def get_ensg_gene_names_hu(ensg_array):\n",
    "    # Load hu dataset to get gene mapping for hoshimoto data\n",
    "    hu_dataset = sc.read_h5ad(os.path.join(\"data\", \"Hu2019\", \"hu_smith.h5ad\"))\n",
    "    hu_gene_pd = hu_dataset.var\n",
    "\n",
    "    k = hu_gene_pd\n",
    "    k = pd.DataFrame(k.values,index=k['ensembl_id'],columns = k.columns)\n",
    "    k = k.drop(['ensembl_id'],axis=1)\n",
    "    ensg_gene_array = []\n",
    "    for ensmbl_id in ensg_array:\n",
    "        ensg_gene_array.append(k.loc[ensmbl_id]['gene_name'])\n",
    "    return ensg_gene_array\n",
    "               \n",
    "gene_names = get_ensg_gene_names_hu(gene_ensg_array)\n",
    "\n",
    "genes['gene_name'] = gene_names\n",
    "genes = genes.rename(columns={0: \"ensembl_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids = [\n",
    "    \"CT1\",\n",
    "    \"CT2\",\n",
    "    \"CT3\",\n",
    "    \"CT4\",\n",
    "    \"CT5\"\n",
    "]\n",
    "\n",
    "study_transcript_counts = []\n",
    "study_gene_names = []\n",
    "subject_barcodes = {}\n",
    "cell_barcodes = []\n",
    "\n",
    "for subject_index, sample_id in enumerate(sample_ids):\n",
    "    \n",
    "    subject_mask = hashimoto_barcodes[\"sample_id\"] == sample_id\n",
    "    subject_data = hashimoto_mtx[subject_mask.values, :]\n",
    "    \n",
    "    cell_barcodes.extend(hashimoto_barcodes[\"barcode\"][subject_mask].values)\n",
    "    \n",
    "    study_transcript_counts.append(subject_data)\n",
    "    study_gene_names.append(genes)\n",
    "    subject_barcodes[\"S%i\" % (subject_index + 1)] = hashimoto_barcodes[\"barcode\"][subject_mask]\n",
    "\n",
    "cell_barcodes = numpy.array(cell_barcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_id_gene_name_lookup = {}\n",
    "\n",
    "ensembl_id_intersection = None\n",
    "\n",
    "for study_index, transcript_counts in enumerate(study_transcript_counts):\n",
    "    \n",
    "    if ensembl_id_intersection is None:\n",
    "        ensembl_id_intersection = set(study_gene_names[study_index][\"ensembl_id\"].values)\n",
    "    else:\n",
    "        ensembl_id_intersection = ensembl_id_intersection.intersection(study_gene_names[study_index][\"ensembl_id\"].values)\n",
    "        \n",
    "    for row in study_gene_names[study_index].iterrows():\n",
    "        ensembl_id_gene_name_lookup[row[1][\"ensembl_id\"]] = row[1][\"gene_name\"]\n",
    "\n",
    "ensembl_id_intersection = list(ensembl_id_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_study_transcript_counts = []\n",
    "combined_batch_indices = []\n",
    "\n",
    "gene_name_index = {gene_name: index for index, gene_name in enumerate(study_gene_names[0][\"ensembl_id\"].values.tolist())}\n",
    "\n",
    "for study_index, transcript_counts in enumerate(study_transcript_counts):\n",
    "    \n",
    "    gene_indices = []\n",
    "    \n",
    "    for gene in ensembl_id_intersection:\n",
    "        gene_indices.append(gene_name_index[gene])\n",
    "    \n",
    "    filtered_study_transcript_counts.append(transcript_counts[:, gene_indices])\n",
    "    \n",
    "    combined_batch_indices.extend([study_index]*transcript_counts.shape[0])\n",
    "\n",
    "combined_transcript_counts = sparse.vstack(filtered_study_transcript_counts)\n",
    "combined_gene_names = [ensembl_id_gene_name_lookup[ensembl_id] for ensembl_id in ensembl_id_intersection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_gene_name_counts = {}\n",
    "new_gene_names = []\n",
    "\n",
    "for gene_index, gene in enumerate(combined_gene_names):\n",
    "    \n",
    "    if gene in existing_gene_name_counts:\n",
    "        existing_gene_name_counts[gene] += 1\n",
    "        gene = \"%s-%i\" % (gene, existing_gene_name_counts[gene] + 1)\n",
    "    else:\n",
    "        existing_gene_name_counts[gene] = 1\n",
    "        \n",
    "    new_gene_names.append(gene)\n",
    "\n",
    "combined_gene_names = new_gene_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ged = GeneExpressionDataset()\n",
    "\n",
    "ged.populate_from_data(\n",
    "    combined_transcript_counts,\n",
    "    gene_names=combined_gene_names,\n",
    "    batch_indices=combined_batch_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliaze variationan autoencoder and training parameters\n",
    "n_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "# Save the training weights\n",
    "latent_pickle_file_name = os.path.join(\"data\", \"Hashimoto2019\", \"hashimoto2019_nepoch_%i_lr_%.1e_latent.pickle\" % (n_epochs, learning_rate))\n",
    "weights_pickle_file_name = os.path.join(\"data\", \"Hashimoto2019\", \"hashimoto2019_nepoch_%i_lr_%.1e_weights.pickle\" % (n_epochs, learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(ged.nb_genes,n_batch=ged.n_batches)\n",
    "trainer=UnsupervisedTrainer(vae,ged,train_size=0.8,frequency=1,seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you can't load existing latent space, train!\n",
    "if not os.path.exists(latent_pickle_file_name):\n",
    "\n",
    "    set_seed(SEED)\n",
    "    \n",
    "    trainer.train(n_epochs=n_epochs, lr=learning_rate)\n",
    "    torch.save(trainer.model.state_dict(), weights_pickle_file_name)\n",
    "    \n",
    "    full = trainer.create_posterior(trainer.model, ged, indices=numpy.arange(len(ged)))\n",
    "    latent, _, _ = full.sequential().get_latent()\n",
    "    \n",
    "    with open(latent_pickle_file_name, 'wb') as latent_pickle_file:\n",
    "        pickle.dump(latent, latent_pickle_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "else:\n",
    "    \n",
    "    weights_pickle_file = torch.load(weights_pickle_file_name)\n",
    "    trainer.model.load_state_dict(weights_pickle_file)\n",
    "    \n",
    "    with open(latent_pickle_file_name, 'rb') as latent_pickle_file:\n",
    "        latent = pickle.load(latent_pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components = 2,random_state=SEED).fit_transform(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = AgglomerativeClustering(n_clusters=13).fit_predict(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "\n",
    "for cluster_index in range(clusters.max()+1):\n",
    "    \n",
    "    x = tsne[clusters == cluster_index, 0]\n",
    "    y = tsne[clusters == cluster_index, 1]\n",
    "    \n",
    "    trace = graph_objects.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        name=\"Cluster %i\" % cluster_index,\n",
    "        mode=\"markers\"\n",
    "    )\n",
    "    \n",
    "    traces.append(trace)\n",
    "\n",
    "figure = graph_objects.Figure(traces)\n",
    "\n",
    "plotly.iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_cell_marker_map = {}\n",
    "cluster_cell_marker_map[3] = 'CD4 T Cells'\n",
    "cluster_cell_marker_map[7] = 'CD4 T Cells'\n",
    "\n",
    "cluster_cell_marker_map[2] = 'CD8 T Cells'\n",
    "cluster_cell_marker_map[9] = 'CD8 T Cells'\n",
    "\n",
    "cluster_cell_marker_map[4] = 'NK Cells'\n",
    "cluster_cell_marker_map[5] = 'NK Cells'\n",
    "\n",
    "cluster_cell_marker_map[11] = 'B Cells'\n",
    "cluster_cell_marker_map[12] = 'B Cells'\n",
    "\n",
    "cluster_cell_marker_map[0] = 'CD14 Monocytes'\n",
    "cluster_cell_marker_map[10] = 'CD14 Monocytes'\n",
    "\n",
    "cluster_cell_marker_map[6] = 'CD16 Monocytes'\n",
    "\n",
    "cluster_cell_marker_map[8] = 'Dendritic Cells'\n",
    "\n",
    "cluster_cell_marker_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_barcodes = {}\n",
    "    \n",
    "for cluster, label in cluster_cell_marker_map.items():\n",
    "    \n",
    "    cluster_mask = clusters == cluster\n",
    "    \n",
    "    cluster_barcodes = cell_barcodes[cluster_mask]\n",
    "    \n",
    "    if label not in label_barcodes:\n",
    "        label_barcodes[label] = set(cluster_barcodes)\n",
    "    else:\n",
    "        label_barcodes[label].update(cluster_barcodes)\n",
    "\n",
    "for subject_id, barcodes in subject_barcodes.items():\n",
    "    label_barcodes[subject_id] = barcodes\n",
    "        \n",
    "GED.write_label_cells_to_file(label_barcodes, os.path.join(\"data\", \"Hashimoto2019\", \"labels.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Note: Uncomment below to explore prominence of a marker in a cluster\n",
    "\n",
    "# GENE = \"CD19\"\n",
    "\n",
    "# gene_index = combined_gene_names.index(GENE)\n",
    "\n",
    "# traces = []\n",
    "    \n",
    "# x = tsne[:, 0]\n",
    "# y = tsne[:, 1]\n",
    "\n",
    "# trace = graph_objects.Scatter(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     name=\"Cluster %i\" % cluster_index,\n",
    "#     mode=\"markers\",\n",
    "#     marker={\n",
    "#         \"color\": combined_transcript_counts[:, gene_index].toarray().flatten()\n",
    "\n",
    "#     })\n",
    "\n",
    "# traces.append(trace)\n",
    "\n",
    "# figure = graph_objects.Figure(traces)\n",
    "\n",
    "# plotly.iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
