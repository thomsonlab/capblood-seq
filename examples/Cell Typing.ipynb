{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import capblood_seq\n",
    "import scvi\n",
    "from scvi.dataset import GeneExpressionDataset\n",
    "import numpy\n",
    "from sparsedat import wrappers \n",
    "import scipy\n",
    "from scvi.models.vae import VAE\n",
    "from scvi.inference import UnsupervisedTrainer\n",
    "from scvi.models.scanvi import SCANVI\n",
    "import scanpy as sc\n",
    "from plotly import offline as plotly\n",
    "from sklearn.manifold import TSNE\n",
    "from plotly import graph_objects\n",
    "from umap import UMAP\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from scvi import set_seed\n",
    "import pickle\n",
    "from scrapi.dataset import Gene_Expression_Dataset as GED\n",
    "from capblood_seq import config\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capblood_seq_data = capblood_seq.load_dataset(\"data\", pipeline_name=\"debris_filtered\")\n",
    "# Combine transcript counts from the different samples into one big matrix\n",
    "\n",
    "cell_sample_index = []\n",
    "combined_transcript_counts = []\n",
    "\n",
    "for sample_index,sample in enumerate(config.SAMPLE_NAMES):\n",
    "    ged = capblood_seq_data._sample_datasets[sample]\n",
    "    cell_transcript_counts = ged.get_cell_transcript_counts()\n",
    "    cell_transcript_counts = cell_transcript_counts.to_array()\n",
    "    combined_transcript_counts.append(cell_transcript_counts)\n",
    "    cell_sample_index.extend([sample_index]*cell_transcript_counts.shape[0])\n",
    "\n",
    "combined_transcript_counts = numpy.concatenate(\n",
    "   combined_transcript_counts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Populate the gene expression set with data\n",
    "ged = GeneExpressionDataset()\n",
    "\n",
    "ged.populate_from_data(\n",
    "    combined_transcript_counts,\n",
    "    gene_names=capblood_seq_data.gene_list,\n",
    "    batch_indices=cell_sample_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliaze variationan autoencoder and training parameters\n",
    "n_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "num_clusters = 13\n",
    "# Save the training weights\n",
    "latent_pickle_file_name = os.path.join(\"data\", \"Dobreva2020\", \"dobreva2020_nepoch_%i_lr_%.1e_latent.pickle\" % (n_epochs, learning_rate))\n",
    "weights_pickle_file_name = os.path.join(\"data\", \"Dobreva2020\", \"dobreva2020_nepoch_%i_lr_%.1e_weights.pickle\" % (n_epochs, learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(ged.nb_genes,n_batch=ged.n_batches)\n",
    "trainer=UnsupervisedTrainer(vae,ged,train_size=0.8,frequency=1,seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you can't load existing latent space, train!\n",
    "if not os.path.exists(latent_pickle_file_name):\n",
    "\n",
    "    set_seed(SEED)\n",
    "    \n",
    "    trainer.train(n_epochs=n_epochs, lr=learning_rate)\n",
    "    torch.save(trainer.model.state_dict(), weights_pickle_file_name)\n",
    "    \n",
    "    full = trainer.create_posterior(trainer.model, ged, indices=numpy.arange(len(ged)))\n",
    "    latent, _, _ = full.sequential().get_latent()\n",
    "    \n",
    "    with open(latent_pickle_file_name, 'wb') as latent_pickle_file:\n",
    "        pickle.dump(latent, latent_pickle_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "else:\n",
    "    \n",
    "    weights_pickle_file = torch.load(weights_pickle_file_name)\n",
    "    trainer.model.load_state_dict(weights_pickle_file)\n",
    "    \n",
    "    full = trainer.create_posterior(trainer.model, ged, indices=numpy.arange(len(ged)))\n",
    "    \n",
    "    with open(latent_pickle_file_name, 'rb') as latent_pickle_file:\n",
    "        latent = pickle.load(latent_pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components = 2,random_state=SEED).fit_transform(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = AgglomerativeClustering(n_clusters=num_clusters).fit_predict(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traces = []\n",
    "\n",
    "for cluster_index in range(clusters.max()+1):\n",
    "    \n",
    "    x = tsne[clusters == cluster_index, 0]\n",
    "    y = tsne[clusters == cluster_index, 1]\n",
    "    \n",
    "    trace = graph_objects.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        name=\"Cluster %i\" % cluster_index,\n",
    "        mode=\"markers\"\n",
    "    )\n",
    "    \n",
    "    traces.append(trace)\n",
    "\n",
    "figure = graph_objects.Figure(traces)\n",
    "\n",
    "plotly.iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "    \n",
    "x = tsne[:, 0]\n",
    "y = tsne[:, 1]\n",
    "\n",
    "trace = graph_objects.Scatter(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    name=\"Cluster %i\" % cluster_index,\n",
    "    mode=\"markers\",\n",
    "    marker={\n",
    "        \"color\": numpy.array(combined_transcript_counts.sum(axis=1)).flatten()\n",
    "    },\n",
    "    text=numpy.array(combined_transcript_counts.sum(axis=1)).flatten()\n",
    ")\n",
    "\n",
    "traces.append(trace)\n",
    "\n",
    "figure = graph_objects.Figure(traces)\n",
    "\n",
    "plotly.iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "    \n",
    "x = tsne[:, 0]\n",
    "y = tsne[:, 1]\n",
    "\n",
    "mt_ratio = numpy.array(combined_transcript_counts[:, numpy.char.startswith(capblood_seq_data.gene_list, \"MT-\")].sum(axis=1)).flatten()\n",
    "mt_ratio = mt_ratio/numpy.array(combined_transcript_counts.sum(axis=1)).flatten()\n",
    "\n",
    "trace = graph_objects.Scatter(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    name=\"Cluster %i\" % cluster_index,\n",
    "    mode=\"markers\",\n",
    "    marker={\n",
    "        \"color\": mt_ratio\n",
    "    },\n",
    "    text=mt_ratio\n",
    ")\n",
    "\n",
    "traces.append(trace)\n",
    "\n",
    "figure = graph_objects.Figure(traces)\n",
    "\n",
    "plotly.iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENE = \"CD14\"\n",
    "\n",
    "gene_index = capblood_seq_data.gene_list.index(GENE)\n",
    "\n",
    "traces = []\n",
    "    \n",
    "x = tsne[:, 0]\n",
    "y = tsne[:, 1]\n",
    "\n",
    "trace = graph_objects.Scatter(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    name=\"Cluster %i\" % cluster_index,\n",
    "    mode=\"markers\",\n",
    "    marker={\n",
    "        \"color\": combined_transcript_counts[:, gene_index].flatten()\n",
    "\n",
    "    })\n",
    "\n",
    "traces.append(trace)\n",
    "\n",
    "figure = graph_objects.Figure(traces)\n",
    "\n",
    "plotly.iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_cell_marker_map = {}\n",
    "cluster_cell_marker_map[2] = 'CD4 T Cells'\n",
    "cluster_cell_marker_map[6] = 'CD4 T Cells'\n",
    "\n",
    "cluster_cell_marker_map[3] = 'CD8 T Cells'\n",
    "cluster_cell_marker_map[9] = 'CD8 T Cells'\n",
    "\n",
    "cluster_cell_marker_map[7] = 'NK Cells'\n",
    "cluster_cell_marker_map[10] = 'NK Cells'\n",
    "\n",
    "cluster_cell_marker_map[11] = 'B Cells'\n",
    "cluster_cell_marker_map[12] = 'B Cells'\n",
    "\n",
    "cluster_cell_marker_map[0] = 'CD14 Monocytes'\n",
    "\n",
    "cluster_cell_marker_map[8] = 'CD16 Monocytes'\n",
    "\n",
    "# cluster_cell_marker_map[1] = 'Unknown'\n",
    "# cluster_cell_marker_map[5] = 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cells = 0\n",
    "\n",
    "for cell_type in set(cluster_cell_marker_map.values()):\n",
    "    \n",
    "    cell_type_cells = clusters == -1\n",
    "    \n",
    "    for cluster in cluster_cell_marker_map:\n",
    "        \n",
    "        if cluster_cell_marker_map[cluster] == cell_type:\n",
    "            cell_type_cells = cell_type_cells | (clusters == cluster)\n",
    "    \n",
    "    num_cell_type_cells = cell_type_cells.sum()\n",
    "    \n",
    "    num_cells += num_cell_type_cells\n",
    "\n",
    "print(num_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "\n",
    "for cell_type in set(cluster_cell_marker_map.values()):\n",
    "    \n",
    "    cell_type_cells = clusters == -1\n",
    "    \n",
    "    for cluster in cluster_cell_marker_map:\n",
    "        \n",
    "        if cluster_cell_marker_map[cluster] == cell_type:\n",
    "            cell_type_cells = cell_type_cells | (clusters == cluster)\n",
    "    \n",
    "    x = tsne[cell_type_cells, 0]\n",
    "    y = tsne[cell_type_cells, 1]\n",
    "    \n",
    "    trace = graph_objects.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        name=\"%s\" % cell_type,\n",
    "        mode=\"markers\"\n",
    "    )\n",
    "    \n",
    "    traces.append(trace)\n",
    "    \n",
    "# Blank the background\n",
    "layout = graph_objects.Layout(\n",
    "    {\n",
    "        \"plot_bgcolor\": \"rgba(255, 255, 255, 0)\",\n",
    "        \"paper_bgcolor\": \"rgba(255, 255, 255, 0)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "figure = graph_objects.Figure(traces, layout=layout)\n",
    "\n",
    "plotly.iplot(figure)\n",
    "\n",
    "# Save for publication!\n",
    "figure.write_image(os.path.join(\"figures\", \"combined_tSNE_labeled_by_cell_type.svg\"))\n",
    "figure.write_html(os.path.join(\"figures\", \"combined_tSNE_labeled_by_cell_type.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = pandas.ExcelWriter(os.path.join(\"data\", \"Dobreva2020\", \"differential_expression.xlsx\"), engine=\"xlsxwriter\")\n",
    "\n",
    "for cluster, cell_type in sorted(cluster_cell_marker_map.items(), key=lambda x: x[0]):\n",
    "\n",
    "    print(cluster)\n",
    "    \n",
    "    cluster_cells = clusters == cluster\n",
    "    non_cluster_cells = ~cluster_cells\n",
    "    \n",
    "    de_df = full.differential_expression_score(\n",
    "        cluster_cells,\n",
    "        non_cluster_cells,\n",
    "        mode=\"change\"\n",
    "    )\n",
    "    \n",
    "    output_df = pandas.DataFrame(index=de_df.index, columns=[\"Bayes Factor\", \"Probability of DE\", \"Cluster Mean\", \"Non Cluster Mean\"])\n",
    "    \n",
    "    output_df[\"Bayes Factor\"] = de_df[\"bayes_factor\"]\n",
    "    output_df[\"Probability of DE\"] = de_df[\"proba_de\"]\n",
    "    output_df[\"Cluster Mean\"] = de_df[\"raw_mean1\"]\n",
    "    output_df[\"Non Cluster Mean\"] = de_df[\"raw_mean2\"]\n",
    "    \n",
    "    output_df = output_df.sort_values(by=\"Bayes Factor\", key=lambda x: numpy.abs(x), ascending=False)\n",
    "    \n",
    "    output_df.to_excel(excel_file, sheet_name=\"Cluster %i - %s\" % (cluster, cell_type))\n",
    "    \n",
    "for cell_type in set(cluster_cell_marker_map.values()):\n",
    "    \n",
    "    print(cell_type)\n",
    "    \n",
    "    cell_type_cells = clusters == -1\n",
    "    \n",
    "    for cluster in cluster_cell_marker_map:\n",
    "        \n",
    "        if cluster_cell_marker_map[cluster] == cell_type:\n",
    "            cell_type_cells = cell_type_cells | (clusters == cluster)\n",
    "            \n",
    "    non_cell_type_cells = ~cell_type_cells\n",
    "    \n",
    "    de_df = full.differential_expression_score(\n",
    "        cell_type_cells,\n",
    "        non_cell_type_cells,\n",
    "        mode=\"change\"\n",
    "    )\n",
    "    \n",
    "    output_df = pandas.DataFrame(index=de_df.index, columns=[\"Bayes Factor\", \"Probability of DE\", \"Cluster Mean\", \"Non Cluster Mean\"])\n",
    "    \n",
    "    output_df[\"Bayes Factor\"] = de_df[\"bayes_factor\"]\n",
    "    output_df[\"Probability of DE\"] = de_df[\"proba_de\"]\n",
    "    output_df[\"Cluster Mean\"] = de_df[\"raw_mean1\"]\n",
    "    output_df[\"Non Cluster Mean\"] = de_df[\"raw_mean2\"]\n",
    "    \n",
    "    output_df = output_df.sort_values(by=\"Bayes Factor\", ascending=False)\n",
    "    \n",
    "    output_df.to_excel(excel_file, sheet_name=\"%s\" % (cell_type))\n",
    "\n",
    "excel_file.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_subtype_labels = {}\n",
    "\n",
    "for cell_type in config.CELL_TYPES:\n",
    "    \n",
    "    if cell_type in config.CELL_SUBTYPES:\n",
    "\n",
    "        for cell_subtype in config.CELL_SUBTYPES[cell_type]:\n",
    "\n",
    "            cell_subtype_labels[\"%s %s\" % (cell_subtype, cell_type)] = cell_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_index = 0\n",
    "\n",
    "for sample_index, sample in enumerate(config.SAMPLE_NAMES):\n",
    "    \n",
    "    ged = capblood_seq_data._sample_datasets[sample]\n",
    "    \n",
    "    num_cells = ged.num_cells\n",
    "    \n",
    "    # Rows are cells\n",
    "    cell_barcodes = numpy.array(ged._cell_transcript_counts.row_names)\n",
    "    \n",
    "    for cluster, label in cluster_cell_marker_map.items():\n",
    "        \n",
    "        if label in ged.get_labels():\n",
    "            ged.delete_label(label)\n",
    "    \n",
    "    for cluster, label in cluster_cell_marker_map.items():\n",
    "        \n",
    "        cluster_mask = clusters == cluster\n",
    "        cluster_mask = cluster_mask[cell_index:cell_index+num_cells]\n",
    "        \n",
    "        label_barcodes = cell_barcodes[cluster_mask]\n",
    "        label = cluster_cell_marker_map[cluster]\n",
    "        \n",
    "        ged.label_cells(label, label_barcodes)\n",
    "        \n",
    "        if label in cell_subtype_labels:        \n",
    "            ged.label_cells(cell_subtype_labels[label], label_barcodes)\n",
    "        \n",
    "    ged.save_labels()\n",
    "    \n",
    "    cell_index += num_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
