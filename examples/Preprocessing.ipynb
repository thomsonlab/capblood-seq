{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "# To reproduce the same clusterings as published\n",
    "random.seed(43)\n",
    "\n",
    "import scrapi\n",
    "\n",
    "from scrapi.dataset import Gene_Expression_Dataset as GED\n",
    "from scrapi.dataset import Data_Mode\n",
    "from scrapi.dataset import Transformation_Method\n",
    "from scrapi.dataset import Normalization_Method\n",
    "\n",
    "from capblood_seq_poc import common as cbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the number of cells you expect\n",
    "MAX_NUM_CELLS = 12000\n",
    "MIN_NUM_CELLS = 1000\n",
    "\n",
    "# How many sources of noise with unique transcript count profile you expect\n",
    "# If you only expect empty droplets, this should be 1. If you expect empty droplets + debris, 2\n",
    "# For blood, we expect debris, empty droplets, and red blood cells\n",
    "NUM_SOURCES_OF_NOISE_EXPECTED = 3\n",
    "\n",
    "# How many cell types you expect at the top level of your hierarchy. For blood, we expect\n",
    "# at least T Cells, B Cells, Monocytes\n",
    "NUM_CELL_TYPES_EXPECTED = 4\n",
    "\n",
    "# How many clusters to try to separate into. Recommend at least num sources of noise, plus\n",
    "# each major cell type, plus each subtype one level below major. For blood, we do\n",
    "# noise (2) + cell types (3) + cell subtypes (2*cell types = 6) = 14\n",
    "MAX_NUM_CLUSTERS = 15\n",
    "\n",
    "# Throw away genes that have no value greater than or equal to this\n",
    "MIN_GENE_COUNT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we execute all our preprocessing for each sample\n",
    "\n",
    "for sample in cbs.SAMPLE_NAMES:\n",
    "    \n",
    "    # First we load the dataset we just initialized\n",
    "    dataset_folder_path = os.path.join(\"data\", sample)\n",
    "    dataset = GED(dataset_folder_path)\n",
    "    \n",
    "    print(dataset.num_cells)\n",
    "    \n",
    "    # Next we filter out barcodes determined as noisy based on their threshold count\n",
    "    # profile. See the Debris Removal notebook for an in-depth example of this\n",
    "    dataset.filter_noise_barcodes(\n",
    "        min_num_cells=MIN_NUM_CELLS,\n",
    "        max_num_cells=MAX_NUM_CELLS,\n",
    "        num_sources_noise_expected=NUM_SOURCES_OF_NOISE_EXPECTED,\n",
    "        min_num_cell_types_expected=NUM_CELL_TYPES_EXPECTED\n",
    "    )\n",
    "    print(dataset.num_cells)\n",
    "    \n",
    "    # Save the workspace at this stage in case we want to work with the unnormalized data\n",
    "    dataset.save(\"debris_filtered\")\n",
    "    \n",
    "    # Filter out any genes that are low count\n",
    "    dataset.filter_low_transcript_counts(MIN_GENE_COUNT)\n",
    "    \n",
    "    # Normalize the transcript counts in a cell by their sum of total transcripts\n",
    "    dataset.normalize_cells(\n",
    "        data_mode=Data_Mode.GENE_PROBABILITIES)\n",
    "    \n",
    "    # Save the normalized data\n",
    "    dataset.save(\"normalized\")\n",
    "    \n",
    "    # Now we're going to do some additional processing for visualization purposes.\n",
    "    # First we do a log transform (with an offset). PCA/t-SNE like this better.\n",
    "    dataset.normalize_genes(\n",
    "        Normalization_Method.LOG_PLUS_1,\n",
    "        use_normalized=True,\n",
    "        parameters=[5000])\n",
    "    \n",
    "    # Transform the data through a few dimensionality reduction techniques\n",
    "    dataset.transform(\n",
    "        Transformation_Method.PCA, num_dimensions=30,\n",
    "        use_normalized=True)\n",
    "    dataset.transform(\n",
    "        Transformation_Method.NMF, num_dimensions=30,\n",
    "        use_normalized=True)\n",
    "    dataset.transform(\n",
    "        Transformation_Method.SVD, num_dimensions=30,\n",
    "        use_normalized=True)\n",
    "    dataset.transform(\n",
    "        Transformation_Method.TSNE, num_dimensions=2,\n",
    "        use_normalized=True)\n",
    "    \n",
    "    # Save the workspace for use in scrap-viz\n",
    "    dataset.save(\"visualization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
