{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import anndata\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import scvi\n",
    "from scvi.dataset import GeneExpressionDataset\n",
    "import numpy\n",
    "from sparsedat import wrappers \n",
    "import scipy\n",
    "from scvi.models.vae import VAE\n",
    "from scvi.inference import UnsupervisedTrainer\n",
    "from scvi.models.scanvi import SCANVI\n",
    "import scanpy as sc\n",
    "from plotly import offline as plotly\n",
    "from sklearn.manifold import TSNE\n",
    "from plotly import graph_objects\n",
    "from umap import UMAP\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "import scanpy as sc\n",
    "import pandas\n",
    "from io import StringIO\n",
    "import anndata\n",
    "from sparsedat import wrappers\n",
    "from scipy.sparse import coo_matrix, vstack\n",
    "import itertools\n",
    "from numpy import load\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "from scvi import set_seed\n",
    "import pickle\n",
    "from scrapi.dataset import Gene_Expression_Dataset as GED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1040"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get healthy venous blood PBMC scRNA-seq data from Lee (2020) dataset (https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE149689)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract healthy venous blood PBMC data from study\n",
    "\n",
    "lee_dataset = sc.read_h5ad(os.path.join(\"data\", \"Lee2020\", \"lee_GSE149689.h5ad\"))\n",
    "\n",
    "lee_obs = lee_dataset.obs\n",
    "\n",
    "lee_gene_df = lee_dataset.var\n",
    "\n",
    "lee_mtx = lee_dataset.X\n",
    "\n",
    "control_subject_descriptors = [\n",
    "    #S1, age: 63, female\n",
    "    'Sample 5_Normal 1 scRNA-seq [SW107]',\n",
    "    #S2, age: 54, female\n",
    "    'Sample 13_Normal 2 scRNA-seq [SW115]',\n",
    "    #S3, age: 67, female\n",
    "    'Sample 14_Normal 3 scRNA-seq [SW116]',\n",
    "    #S4, age: 64, male\n",
    "    'Sample 19_Normal 4 scRNA-seq [SW121]'\n",
    "]\n",
    "\n",
    "study_transcript_counts = []\n",
    "study_gene_names = []\n",
    "subject_barcodes = {}\n",
    "cell_barcodes = []\n",
    "\n",
    "for subject_index, subject_descriptor in enumerate(control_subject_descriptors):\n",
    "    subject_mask = (lee_obs['sample_description']==subject_descriptor)\n",
    "    subject_data = lee_mtx[subject_mask.values,:]\n",
    "    \n",
    "    cell_barcodes.extend(lee_obs[\"barcode\"][subject_mask].values)\n",
    "    \n",
    "    study_transcript_counts.append(subject_data)\n",
    "    study_gene_names.append(lee_gene_df)\n",
    "    subject_barcodes[\"S%i\" % (subject_index + 1)] = lee_obs[\"barcode\"][subject_mask]\n",
    "\n",
    "cell_barcodes = numpy.array(cell_barcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine transcripts into a single matrix. \n",
    "# Combine gene names (avoid duplicates).\n",
    "# Get mask for batch indices.\n",
    "ensembl_id_gene_name_lookup = {}\n",
    "\n",
    "ensembl_id_intersection = None\n",
    "\n",
    "for study_index, transcript_counts in enumerate(study_transcript_counts):\n",
    "    \n",
    "    if ensembl_id_intersection is None:\n",
    "        ensembl_id_intersection = set(study_gene_names[study_index][\"ensembl_id\"].values)\n",
    "    else:\n",
    "        ensembl_id_intersection = ensembl_id_intersection.intersection(study_gene_names[study_index][\"ensembl_id\"].values)\n",
    "        \n",
    "    for row in study_gene_names[study_index].iterrows():\n",
    "        ensembl_id_gene_name_lookup[row[1][\"ensembl_id\"]] = row[1][\"gene_name\"]\n",
    "\n",
    "ensembl_id_intersection = list(ensembl_id_intersection)\n",
    "\n",
    "filtered_study_transcript_counts = []\n",
    "combined_batch_indices = []\n",
    "\n",
    "for study_index, transcript_counts in enumerate(study_transcript_counts):\n",
    "    \n",
    "    gene_name_index = {gene_name: index for index, gene_name in enumerate(study_gene_names[0][\"ensembl_id\"].values.tolist())}\n",
    "    \n",
    "    gene_indices = []\n",
    "    \n",
    "    for gene in ensembl_id_intersection:\n",
    "        gene_indices.append(gene_name_index[gene])\n",
    "    \n",
    "    filtered_study_transcript_counts.append(transcript_counts[:, gene_indices])\n",
    "    \n",
    "    combined_batch_indices.extend([study_index]*transcript_counts.shape[0])\n",
    "\n",
    "combined_transcript_counts = sparse.vstack(filtered_study_transcript_counts)\n",
    "combined_gene_names = [ensembl_id_gene_name_lookup[ensembl_id] for ensembl_id in ensembl_id_intersection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_gene_name_counts = {}\n",
    "new_gene_names = []\n",
    "\n",
    "for gene_index, gene in enumerate(combined_gene_names):\n",
    "    \n",
    "    if gene in existing_gene_name_counts:\n",
    "        existing_gene_name_counts[gene] += 1\n",
    "        gene = \"%s-%i\" % (gene, existing_gene_name_counts[gene] + 1)\n",
    "    else:\n",
    "        existing_gene_name_counts[gene] = 1\n",
    "        \n",
    "    new_gene_names.append(gene)\n",
    "\n",
    "combined_gene_names = new_gene_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ged = GeneExpressionDataset()\n",
    "\n",
    "ged.populate_from_data(\n",
    "    combined_transcript_counts,\n",
    "    gene_names=combined_gene_names,\n",
    "    batch_indices=combined_batch_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliaze variationan autoencoder and training parameters\n",
    "n_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "num_clusters = 15\n",
    "# Save the training weights\n",
    "latent_pickle_file_name = os.path.join(\"data\", \"Lee2020\", \"lee2020_nepoch_%i_lr_%.1e_latent.pickle\" % (n_epochs, learning_rate))\n",
    "weights_pickle_file_name = os.path.join(\"data\", \"Lee2020\", \"lee2020_nepoch_%i_lr_%.1e_weights.pickle\" % (n_epochs, learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(ged.nb_genes,n_batch=ged.n_batches)\n",
    "trainer=UnsupervisedTrainer(vae,ged,train_size=0.8,frequency=1,seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you can't load existing latent space, train!\n",
    "if not os.path.exists(latent_pickle_file_name):\n",
    "\n",
    "    set_seed(SEED)\n",
    "    \n",
    "    trainer.train(n_epochs=n_epochs, lr=learning_rate)\n",
    "    torch.save(trainer.model.state_dict(), weights_pickle_file_name)\n",
    "    \n",
    "    full = trainer.create_posterior(trainer.model, ged, indices=numpy.arange(len(ged)))\n",
    "    latent, _, _ = full.sequential().get_latent()\n",
    "    \n",
    "    with open(latent_pickle_file_name, 'wb') as latent_pickle_file:\n",
    "        pickle.dump(latent, latent_pickle_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "else:\n",
    "    \n",
    "    set_seed(SEED)\n",
    "    \n",
    "    weights_pickle_file = torch.load(weights_pickle_file_name)\n",
    "    trainer.model.load_state_dict(weights_pickle_file)\n",
    "    \n",
    "    full = trainer.create_posterior(trainer.model, ged, indices=numpy.arange(len(ged)))\n",
    "    \n",
    "    with open(latent_pickle_file_name, 'rb') as latent_pickle_file:\n",
    "        latent = pickle.load(latent_pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components = 2,random_state=SEED).fit_transform(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = AgglomerativeClustering(n_clusters=num_clusters).fit_predict(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "\n",
    "for cluster_index in range(clusters.max()+1):\n",
    "    \n",
    "    x = tsne[clusters == cluster_index, 0]\n",
    "    y = tsne[clusters == cluster_index, 1]\n",
    "    \n",
    "    trace = graph_objects.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        name=\"Cluster %i\" % cluster_index,\n",
    "        mode=\"markers\"\n",
    "    )\n",
    "    \n",
    "    traces.append(trace)\n",
    "\n",
    "figure = graph_objects.Figure(traces)\n",
    "\n",
    "plotly.iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "    \n",
    "x = tsne[:, 0]\n",
    "y = tsne[:, 1]\n",
    "\n",
    "trace = graph_objects.Scatter(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    name=\"Cluster %i\" % cluster_index,\n",
    "    mode=\"markers\",\n",
    "    marker={\n",
    "        \"color\": numpy.array(combined_transcript_counts.sum(axis=1)).flatten()\n",
    "    },\n",
    "    text=numpy.array(combined_transcript_counts.sum(axis=1)).flatten()\n",
    ")\n",
    "\n",
    "traces.append(trace)\n",
    "\n",
    "figure = graph_objects.Figure(traces)\n",
    "\n",
    "plotly.iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = []\n",
    "    \n",
    "x = tsne[:, 0]\n",
    "y = tsne[:, 1]\n",
    "\n",
    "mt_ratio = numpy.array(combined_transcript_counts[:, numpy.char.startswith(combined_gene_names, \"MT-\")].sum(axis=1)).flatten()\n",
    "mt_ratio = mt_ratio/numpy.array(combined_transcript_counts.sum(axis=1)).flatten()\n",
    "\n",
    "trace = graph_objects.Scatter(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    name=\"Cluster %i\" % cluster_index,\n",
    "    mode=\"markers\",\n",
    "    marker={\n",
    "        \"color\": mt_ratio\n",
    "    },\n",
    "    text=mt_ratio\n",
    ")\n",
    "\n",
    "traces.append(trace)\n",
    "\n",
    "figure = graph_objects.Figure(traces)\n",
    "\n",
    "plotly.iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENE = \"CD14\"\n",
    "\n",
    "gene_index = combined_gene_names.index(GENE)\n",
    "\n",
    "traces = []\n",
    "    \n",
    "x = tsne[:, 0]\n",
    "y = tsne[:, 1]\n",
    "\n",
    "trace = graph_objects.Scatter(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    name=\"Cluster %i\" % cluster_index,\n",
    "    mode=\"markers\",\n",
    "    marker={\n",
    "        \"color\": combined_transcript_counts[:, gene_index].toarray().flatten()\n",
    "\n",
    "    })\n",
    "\n",
    "traces.append(trace)\n",
    "\n",
    "figure = graph_objects.Figure(traces)\n",
    "\n",
    "plotly.iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_cell_marker_map = {}\n",
    "\n",
    "\n",
    "cluster_cell_marker_map[3] = 'CD14 Monocytes'\n",
    "cluster_cell_marker_map[7] = 'CD14 Monocytes'\n",
    "\n",
    "cluster_cell_marker_map[13] = 'CD16 Monocytes'\n",
    "\n",
    "cluster_cell_marker_map[2] = 'B Cells'\n",
    "cluster_cell_marker_map[4] = 'NK Cells'\n",
    "\n",
    "cluster_cell_marker_map[10] = 'CD8 T Cells'\n",
    "cluster_cell_marker_map[6] = 'CD4 T Cells'\n",
    "\n",
    "# cluster_cell_marker_map[0] = \"Dendritic Cells\"\n",
    "#cluster_cell_marker_map[11] = \"Red Blood Cells\"\n",
    "#cluster_cell_marker_map[1] = \"Debris\"\n",
    "#cluster_cell_marker_map[5] = \"Debris\"\n",
    "#cluster_cell_marker_map[9] = \"Debris\"\n",
    "#cluster_cell_marker_map[14] = \"Debris\"\n",
    "\n",
    "#cluster_cell_marker_map[2] = \"Dendritic Cells\"\n",
    "#cluster_cell_marker_map[3] = \"Debris\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_barcodes = {}\n",
    "    \n",
    "for cluster, label in cluster_cell_marker_map.items():\n",
    "    \n",
    "    cluster_mask = clusters == cluster\n",
    "    \n",
    "    cluster_barcodes = cell_barcodes[cluster_mask]\n",
    "    \n",
    "    if label not in label_barcodes:\n",
    "        label_barcodes[label] = set(cluster_barcodes)\n",
    "    else:\n",
    "        label_barcodes[label].update(cluster_barcodes)\n",
    "\n",
    "for subject_id, barcodes in subject_barcodes.items():\n",
    "    label_barcodes[subject_id] = barcodes\n",
    "        \n",
    "GED.write_label_cells_to_file(label_barcodes, os.path.join(\"data\", \"Lee2020\", \"labels.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
